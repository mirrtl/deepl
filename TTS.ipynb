{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfU7Vf1QFmESCLCP4J6JxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirrtl/deepl/blob/main/TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка модели mini-jenny-30H в моей работе будет осуществляться как стандартными методами, так и методами направленными на оценку специфик голоса jenny.\n",
        "\n",
        "**Для работы кода надо скачать прикрепленный файл с тестовым аудио или же использовать свое(затем изменить путь на аудио). Также прикреплен файл со сгенерированным аудио, на котором проводилась оценка.**"
      ],
      "metadata": {
        "id": "BMUeHIkd6NRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**План оценки модели**\n",
        "Отбор аудио состоял из нахождения отрывка речи, в моем случае это был отрывок с чтением стиха, с голосом и интонацией максимально похожими на голос Дженни. Эти факторы играют большую роль в двух метриках, которые будут рассмотрены здесь\n",
        "\n",
        "**1 метрика - WER**\n",
        "\n",
        "WER (Word Error Rate) — это метрика, которая используется для оценки качества распознанной речи или текстового результата TTS (Text-to-Speech) моделей. Она показывает, насколько сильно сгенерированный текст отличается от эталонного (референсного) текста.\n",
        "\n",
        "**2 метрика - STOI**\n",
        "\n",
        "Метрика STOI(Short-Time Objective Intelligibility) Измеряет корреляцию между огибающими двух сигналов. В нашем случае сигналы это записи голосов(идеальный и сгенерированный).\n",
        "\n",
        "**3 метрика**\n",
        "\n",
        "Эта метрика показывает отношения выбросов частот в спектре голосов к общему числу частей спектра. То есть показывает процентное соотношение выбросов.\n",
        "Реализуется так, что выбросами частоты считаются, если отклоняются от средней частоты более чем на 3 стандартных отклонения и если амплитуда этих колебания превышает определенный порог.\n",
        "\n",
        "**Причина выбора метрик и описание**\n",
        "\n",
        "Первая и третья метрика, позволяют хорошо оценить сгенерированное аудио без отобранного аудио, они позволяют выявить ошибки на уровне самой генерации(выбросы, шумы и тд.) и узнать прошла ли генерация самого текста без ошибок.\n",
        "\n",
        "2 метрика позволяет оценить как насколько похожи сгенерированное аудио с тем аудио, которое мы отобрали с целью сгенерировать похожее.\n",
        "Она покажет степень похожести двух аудио\n",
        "\n",
        "**Промт и описание для генерации**\n",
        "\n",
        " *prompt = '''The movement of your hands is the long, golden running of light from a rising sun;\n",
        "It is the hopping of birds upon a garden-path;\n",
        "As the perfume of jonquils, you come forth in the morning.'''*\n",
        "\n",
        "*description = \"Jenny speaks at a slow pace with an animated delivery in a confined environment with clear audio, audio must be 15 seconds long\"*\n",
        "\n",
        "Описание было выбрано таким, поскольку выбранное аудио состояло из чтения стиха в медленном темпе, без шумов и в ограниченном диапазоне частот. Так же указался желательное время длины аудио\n"
      ],
      "metadata": {
        "id": "Uo8QUeEF9oI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/huggingface/parler-tts.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HBGGfEfTvx9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iyKHX1Ft80oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "41-MmYQj9AkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3BrJ1I8tAJg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from parler_tts import ParlerTTSForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "import soundfile as sf\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\", use_fast=True)\n",
        "# Текст, на основе которого будет проводиться генерация\n",
        "prompt = '''The movement of your hands is the long, golden running of light from a rising sun;\n",
        "It is the hopping of birds upon a garden-path;\n",
        "As the perfume of jonquils, you come forth in the morning.'''\n",
        "# Описание критериев для генерации\n",
        "description = \"Jenny speaks at a slow pace with an animated delivery in a confined environment with clear audio, audio must be 15 seconds long\"\n",
        "\n",
        "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
        "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
        "audio_arr = generation.cpu().numpy().squeeze()\n",
        "sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1 метрика - WER**\n"
      ],
      "metadata": {
        "id": "7zFwba_q6MMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jiwer\n",
        "from speech_recognition import Recognizer, AudioFile, UnknownValueError, RequestError\n",
        "from jiwer import Compose\n",
        "\n",
        "# Создание кастомного трансформера для предобработки текстов\n",
        "custom_transform = Compose([\n",
        "    jiwer.RemovePunctuation(),  # Удалить пунктуацию\n",
        "    jiwer.ToLowerCase(),        # Преобразовать в нижний регистр\n",
        "    jiwer.RemoveMultipleSpaces(),# Удалить лишние пробелы\n",
        "    lambda s: s.replace(\"\\n\", \" \") # Удалить символы перевода на новую строку\n",
        "])\n",
        "\n",
        "recognizer = Recognizer()\n",
        "\n",
        "# Исходный текст\n",
        "ground_truth = '''The movement of your hands is the long, golden running of light from a rising sun;\n",
        "It is the hopping of birds upon a garden-path;\n",
        "As the perfume of jonquils, you come forth in the morning.'''\n",
        "recognized_texts = []\n",
        "# Распознавание аудио\n",
        "with AudioFile(\"parler_tts_out.wav\") as source:\n",
        "    audio = recognizer.record(source)\n",
        "recognized_text = recognizer.recognize_google(audio, language=\"en-US\")\n",
        "recognized_texts.append(recognized_text)\n",
        "\n",
        "\n",
        "# Применение кастомного трансформера\n",
        "ground_truth_transformed = custom_transform(ground_truth)\n",
        "recognized_texts_transformed = [custom_transform(rt) for rt in recognized_texts]\n",
        "\n",
        "# Вычисление WER\n",
        "wer = jiwer.wer(ground_truth_transformed, recognized_texts_transformed[0])\n",
        "print(f\"Word Error Rate (WER): {wer:.2f}\")\n",
        "\n",
        "# Вывод распознанных текстов\n",
        "print(f\"Ground Truth: {ground_truth_transformed}\")\n",
        "print(f\"Recognized  : {recognized_texts_transformed[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZUUU0thKvxRB",
        "outputId": "7b5ea18a-4d19-49aa-bc58-5971401c3a82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Error Rate (WER): 0.08\n",
            "Ground Truth: the movement of your hands is the long golden running of light from a rising sun it is the hopping of birds upon a gardenpath as the perfume of jonquils you come forth in the morning\n",
            "Recognized  : the movements of your hands is the long golden running of light from a rising sun it is the hopping of birds upon a garden path as the perfume of jonquils you come forth in the morning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2 метрика - STOI**"
      ],
      "metadata": {
        "id": "XQ-wpgYLI2wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import pystoi\n",
        "\n",
        "# Загрузить тестовое и сгенерированное аудио с разными частотами дискретизации\n",
        "reference, rate_ref = librosa.load('spc249_inexcelsis_ams_64kb (1) (mp3cut.net).wav', sr=16000)\n",
        "degraded, rate_deg = librosa.load('parler_tts_out.wav', sr=16000)\n",
        "\n",
        "min_len = min(reference.shape[0], degraded.shape[0])\n",
        "reference = reference[:min_len]\n",
        "degraded = degraded[:min_len]\n",
        "\n",
        "# STOI оценка\n",
        "stoi_score = pystoi.stoi(reference, degraded, rate_ref, extended=False)\n",
        "print(f\"STOI оценка: {stoi_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsUJLRYUIvyz",
        "outputId": "c7dc5986-82e2-4c0b-a22f-2f670c81223d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STOI оценка: 0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3 метрика**\n"
      ],
      "metadata": {
        "id": "LEu0LAHna7FV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Во время анализирования задания, появилась идея реализовать метрику, которая находила бы выбросы в спектре голоса, те значения частоты которые не должны соответствовать голосу Дженни. Такая метрика в этом случае (скорее всего) должна показывать хорошие результаты, поскольку сгенерированная запись голоса находится примерно в одной тональности, и каких-то высоких и низких частот не должно присутствовать. Значения частот спектра считаются выбросом, если амплитуда колебания превышают определенный уровень amplitude_threshold"
      ],
      "metadata": {
        "id": "j8Uvwdzgn06b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка аудиофайла\n",
        "y, sr = librosa.load(\"parler_tts_out.wav\", sr=None)\n",
        "\n",
        "# Вычисление спектрограммы\n",
        "S = librosa.stft(y)\n",
        "S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
        "\n",
        "# Вычисление среднего спектра и стандартного отклонения\n",
        "mean_spectrum = np.mean(S_db, axis=1)  # Среднее по времени\n",
        "std_spectrum = np.std(S_db, axis=1)    # Стандартное отклонение по времени\n",
        "\n",
        "# Порог для выбросов\n",
        "threshold = mean_spectrum + 3 * std_spectrum\n",
        "\n",
        "# Минимальный порог амплитуды (например, -60 dB)\n",
        "amplitude_threshold = -60\n",
        "\n",
        "# Определение выбросов\n",
        "anomalies = (S_db > threshold[:, np.newaxis]) & (S_db > amplitude_threshold)\n",
        "\n",
        "# Количество выбросов\n",
        "num_anomalies = np.sum(anomalies)\n",
        "\n",
        "# Общее количество точек\n",
        "total_points = S_db.size\n",
        "\n",
        "# Доля выбросов\n",
        "fraction_anomalies = num_anomalies / total_points\n",
        "\n",
        "print(f\"Доля выбросов: {fraction_anomalies:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aKflWQujwzp8",
        "outputId": "3318245e-a434-4dd0-da9b-c1165a845016"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доля выбросов: 0.0089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Отчет**"
      ],
      "metadata": {
        "id": "I5c296hWE4u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем выводы по полученным метрикам.\n",
        "\n",
        "**1 метрика - WER**\n",
        "\n",
        "wer = 0.08 - доля неверно написанных слов. Означает что 8% слов написано неверно. В нашем случае модель распознования речи посчитала что слово groundpath должно писать раздельно как ground path. За ошибку такую неточность можно не считать\n",
        "\n",
        "**2 метрика - STOI**\n",
        "\n",
        "STOI = 0.22. В идеальном случае метрика равна 1. По такому значению можно сказать, что какая-то корреляцию все же есть, но он очень мала. Это происходит из-за того, что модель не смогла подобрать очень похожую интонацию, поскольку корреляция определяется по времени. Благодаря такой метрике можно говорить о правильности подобранной итонации.\n",
        "\n",
        "**3 метрика**\n",
        "метрика = 0.0089. Идеальным значением является 0. В нашем случае метрика очень близка к ней, что говорит о малом колличестве шумов и статистически аномальных значения спектра.\n",
        "\n"
      ],
      "metadata": {
        "id": "rrmPcnMuI5H2"
      }
    }
  ]
}